UNet(
  (encoder1): EncoderBlock(
    (conv_block): ConvBlock(
      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (encoder2): EncoderBlock(
    (conv_block): ConvBlock(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (encoder3): EncoderBlock(
    (conv_block): ConvBlock(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (encoder4): EncoderBlock(
    (conv_block): ConvBlock(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (dropout1): DropoutBlock(
    (dropout): Dropout(p=0.33, inplace=False)
  )
  (center): ConvBlock(
    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (dropout2): DropoutBlock(
    (dropout): Dropout(p=0.33, inplace=False)
  )
  (decoder4): DecoderBlock(
    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))
    (conv_block): ConvBlock(
      (conv1): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
  (decoder3): DecoderBlock(
    (up): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
    (conv_block): ConvBlock(
      (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
  (decoder2): DecoderBlock(
    (up): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))
    (conv_block): ConvBlock(
      (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
  (decoder1): DecoderBlock(
    (up): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))
    (conv_block): ConvBlock(
      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
  (final_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
)
Loading training data  COCO_with_CLIP_embeddings.pickle
Loaded 82783 training records
First Image:  (64, 64, 3)
0.00015540899959176624 (64, 64, 3)
0.028058334845816213 (64, 64, 3)
0.10143374638853864 (64, 64, 3)
0.21321178182447698 (64, 64, 3)
0.35262241279454787 (64, 64, 3)
0.5062331572977075 (64, 64, 3)
0.659243325125842 (64, 64, 3)
0.7969100927867507 (64, 64, 3)
0.9059690028579283 (64, 64, 3)
0.9759120199306612 (64, 64, 3)
Created 10 forward diffusion images in outputs
Calling model() with:  torch.Size([1, 3, 64, 64])


Traceback (most recent call last):
  File "./diffusion.py", line 101, in <module>
    result = model(image_tensor)
  File "/mnt/ceph/sheneman/src/techtalk/diffusion/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/ceph/sheneman/src/techtalk/diffusion/unet.py", line 81, in forward
    x = self.decoder4(x, enc4)
  File "/mnt/ceph/sheneman/src/techtalk/diffusion/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/ceph/sheneman/src/techtalk/diffusion/unet.py", line 36, in forward
    x = self.conv_block(x)
  File "/mnt/ceph/sheneman/src/techtalk/diffusion/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/ceph/sheneman/src/techtalk/diffusion/unet.py", line 12, in forward
    x = self.relu(self.conv1(x))
  File "/mnt/ceph/sheneman/src/techtalk/diffusion/venv/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/ceph/sheneman/src/techtalk/diffusion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/mnt/ceph/sheneman/src/techtalk/diffusion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Given groups=1, weight of size [256, 768, 3, 3], expected input[1, 1024, 8, 8] to have 768 channels, but got 1024 channels instead

